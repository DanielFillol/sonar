package gpt

import "log"

// OpenAIRequest represents the payload sent to the OpenAI API for chat completions.
type OpenAIRequest struct {
	// Model specifies the identifier of the model to use for generating the completion.
	// Example: "gpt-3.5-turbo".
	Model string `json:"model"`

	// Messages is an array of message objects that constitute the conversation history.
	// Each message should include a role ("system", "user", or "assistant") and content.
	Messages []Message `json:"messages"`
}

func NewGPTPayload() *OpenAIRequest {
	return &OpenAIRequest{
		Model: "chatgpt-4o-latest",
	}
}

func (o *OpenAIRequest) NewMessage(message Message) {
	o.Messages = append(o.Messages, message)
}

// Message represents a single message in the conversation.
type Message struct {
	// Role specifies the role of the message author.
	// Acceptable values are "system", "user", or "assistant".
	Role string `json:"role"`

	// Content contains the text content of the message.
	Content string `json:"content"`
}

// OpenAIResponse represents the response received from the OpenAI API.
type OpenAIResponse struct {
	// ID is a unique identifier assigned to the completion response.
	ID string `json:"id"`

	// Object specifies the type of object returned. For chat completions, this is typically "chat.completion".
	Object string `json:"object"`

	// Created is a Unix timestamp (in seconds) indicating when the completion was generated.
	Created int64 `json:"created"`

	// Model indicates the identifier of the model used to generate the response.
	Model string `json:"model"`

	// Choices is an array of completion choices returned by the API.
	Choices []Choice `json:"choices"`

	// Usage provides information about token usage for the request and response.
	Usage UsageInfo `json:"usage"`
}

// Choice represents a single completion choice from the API.
type Choice struct {
	// Index indicates the position of this completion choice in the list.
	Index int `json:"index"`

	// Message contains the message generated by the model for this choice.
	Message Message `json:"message"`

	// FinishReason describes the reason why the model stopped generating tokens.
	// Possible values include "stop", "length", "content_filter", or "null" (if the reason is unknown).
	FinishReason string `json:"finish_reason"`
}

// UsageInfo provides information about token usage for the request and response.
type UsageInfo struct {
	// PromptTokens is the number of tokens consumed by the input prompt.
	PromptTokens int `json:"prompt_tokens"`

	// CompletionTokens is the number of tokens generated in the completion.
	CompletionTokens int `json:"completion_tokens"`

	// TotalTokens is the total number of tokens used (prompt + completion).
	TotalTokens int `json:"total_tokens"`
}

func ClassifyLawField(system, query string) (*string, error) {
	log.Println("Classificando o campo do Direito")
	lawField, err := Search(system, query, "gpt-4o-mini")
	if err != nil {
		return nil, err
	}
	log.Println("Campo do Direito: " + lawField.Choices[0].Message.Content)
	return &lawField.Choices[0].Message.Content, err
}

func GetRelevantAuthors(system, query string) (*string, error) {
	log.Println("Selecionando Doutrinadores")
	authors, err := Search(system, query, "gpt-4o-mini")
	if err != nil {
		return nil, err
	}
	log.Println("Doutrinadores selecionados: " + authors.Choices[0].Message.Content)
	return &authors.Choices[0].Message.Content, nil
}
